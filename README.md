**Hand Gesture Recognition using Machine Learning**

🚀 Task: Gesture-Based Human-Computer Interaction System

**📌 Project Overview**

This project implements a hand gesture recognition model that classifies different hand gestures from image data using machine learning techniques. The goal is to build an intuitive system for gesture-based control, enabling natural human-computer interaction through vision-based inputs.

**📂 Dataset:** LeapGestRecog

🔗 Kaggle Link: [LeapHand Gesture Dataset (LeapGestRecog)](https://www.kaggle.com/datasets/gti-upm/leapgestrecog)

The dataset contains 20,000+ grayscale gesture images.

10 gesture classes performed by 10 subjects, recorded using a Leap Motion Controller.

Images are 320×240 pixels, organized into folders for subjects and gesture types.

**Example Gestures:**

Palm

Fist

Two Fingers

Thumb Up / Down

Pointing

Others

**🎯 Objective**

Develop a machine learning pipeline to classify static hand gestures.

Use image processing to extract meaningful features.

Train a model for real-time or image-based prediction.

**⚙️ Technologies Used**

Python

OpenCV (image preprocessing)

NumPy (numerical computations)

scikit-learn (model training and evaluation)

matplotlib (visualization)

Optional: TensorFlow / Keras for deep learning extension
